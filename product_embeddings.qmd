---
title: "Untitled"
format: html
editor: visual
---

## Notes

-   Data sources:

    -   https://archive.ics.uci.edu/dataset/352/online+retail

    -   https://archive.ics.uci.edu/dataset/502/online+retail+ii

-   Other literature:

    -   https://anhornsby.github.io/embeddings-retail/#/

    -   https://www.dunnhumby.com/resources/blog/science-data/en/how-to-solve-the-problem-of-product-similarity-with-data-science/

    -   https://www.youtube.com/watch?v=0uWCGn-1KRE

## Running Code

...

```{r message=FALSE}
library(tidyverse)
library(magrittr)
library(ggplot2)
library(tictoc)
library(word2vec)

source("./product_embeddings_fn.r")

```

```{r}
transactions_df <- readr::read_csv("../dunnhumby_complete/dunnhumby_The-Complete-Journey CSV/transaction_data.csv")
transactions_df %<>% mutate(list_price = (SALES_VALUE-RETAIL_DISC-COUPON_DISC)/QUANTITY ) 
transactions_df %<>% mutate( month = floor(((DAY-1) %% 365 ) / 31) )
transactions_df %<>% mutate( wday = ((DAY-1) %% 7) )
transactions_df
```

```{r}
product_df <- readr::read_csv("../dunnhumby_complete/dunnhumby_The-Complete-Journey CSV/product.csv")
product_df
```

```{r}

# make sure that there is only one row per transaction id/product id combination
transactions_summary_df <- transactions_df %>% 
      group_by(month, wday, BASKET_ID, PRODUCT_ID) %>% 
      summarize(quantity = sum(QUANTITY))

# plot histogram of product frequencies
product_freq <- transactions_summary_df %>% 
      group_by(PRODUCT_ID) %>% 
      summarize(total_quantity = sum(quantity)) %>% 
      arrange(desc(total_quantity))
# ggplot(product_freq, aes(n)) + geom_histogram()

```

```{r}
# identify all product ids which have been bought fewer than five times
unpopular_products <- product_freq %>% filter(total_quantity <= 5) %>% select(PRODUCT_ID)

# drop all of those rarely purchased products
transactions_summary_df %<>% anti_join( unpopular_products, by = "PRODUCT_ID" )
```

```{r}

# determine and mark the top 500 products as calibration targets for hyper-parameter tuning
n_test_products <- 200
calibration_products_df <- sample_n(product_freq[1:1500,], n_test_products)
calibration_products <- calibration_products_df$PRODUCT_ID %>% as.character()
#transactions_summary_df %<>% mutate( is_calibration_product = (PRODUCT_ID %in% calibration_products) )

```

```{r}

list_prices_df <- transactions_df %>%
                semi_join( calibration_products_df, by = "PRODUCT_ID" ) %>%
                group_by(PRODUCT_ID) %>% 
                filter( QUANTITY > 0, list_price > 0 ) %>%
                summarize(list_price_avg = mean(list_price, na.rm=T), 
                          list_price_sd = sd(list_price, na.rm=T) ) 
log_list_prices <- list_prices_df$list_price_avg %T>% 
                {names(.) <- list_prices_df$PRODUCT_ID} %>% 
                log()
#log_list_prices %<>% c( log_list_prices %T>% {names(.) <- paste0(list_prices_df$PRODUCT_ID, "X")} )

```

```{r}

# transactions_summary_df %<>%
#   group_by(PRODUCT_ID) %>% 
#   mutate( alt_label = ifelse(!is_calibration_product, FALSE, sample_bool_approx_equal_n(n())) ) %>%
#   mutate( PRODUCT_ID_ALT = ifelse(alt_label, paste0(as.character(PRODUCT_ID), "X"), 
#                                   as.character(PRODUCT_ID)) ) %>%
#   select(-quantity, -is_calibration_product, -alt_label)

# roll up transactions to strings
transaction_baskets_df <- 
  transactions_summary_df %>% 
  group_by(BASKET_ID) %>% 
  summarize( basket = list(c(PRODUCT_ID, paste0("M",month[1]), paste0("WD",wday[1]))) )

transaction_baskets_df$basket %<>% sapply( function(x) paste(sample(x), collapse = " "))

```

```{r}
# products_test <- transactions_summary_df %>% ungroup %>% select(PRODUCT_ID, PRODUCT_ID_ALT) %>% filter(PRODUCT_ID != PRODUCT_ID_ALT) %>% distinct()
# products_test$PRODUCT_ID %<>% as.character()
# products_test$PRODUCT_ID_ALT %<>% as.character()
```

```{r}

#volumes_total <-
#    transactions_df %>% 
#    group_by(PRODUCT_ID) %>%
#    summarize(total = sum(QUANTITY))
#volumes_correlation <- volumes_total %>% filter(total > 250)

seasonality_weekly_mat <-
    transactions_df %>% 
    semi_join(calibration_products_df, by = "PRODUCT_ID") %>% 
    group_by(PRODUCT_ID, wday) %>%
    summarize(quantity = sum(QUANTITY)) %>%
    #group_by(PRODUCT_ID) %>%
    #mutate(quantity = quantity/sum(quantity)) %>%
    pivot_wider(names_from = "wday", values_from = "quantity", values_fill = 0) %>% 
    select(PRODUCT_ID, `0`, `1`, `2`, `3`, `4`, `5`, `6`) %>% 
    as.data.frame()

rownames(seasonality_weekly_mat) <- seasonality_weekly_mat$PRODUCT_ID
seasonality_weekly_mat %<>% .[,-1] %>% as.matrix()
seasonality_weekly_corr_upper <- corr_posterior_mat(seasonality_weekly_mat)
seasonality_weekly_corr_upper %<>% .[calibration_products, calibration_products]
```

```{r}
seasonality_monthly_mat <-
    transactions_df %>% 
    semi_join(calibration_products_df, by = "PRODUCT_ID") %>% 
    group_by(PRODUCT_ID, month) %>%
    summarize(quantity = sum(QUANTITY)) %>%
    group_by(PRODUCT_ID) %>%
    mutate(quantity = quantity/sum(quantity)) %>%
    pivot_wider(names_from = "month", values_from = "quantity", values_fill = 0)

seasonality_monthly_mat %<>%
    select(PRODUCT_ID, `0`, `1`, `2`, `3`, `4`, `5`, `6`, `7`, `8`, `9`, `10`, `11`) %>% 
    as.data.frame()
rownames(seasonality_monthly_mat) <- seasonality_monthly_mat$PRODUCT_ID
seasonality_monthly_mat %<>% .[,-1] %>% as.matrix()
seasonality_monthly_corr_upper <- corr_posterior_mat(seasonality_monthly_mat)
seasonality_monthly_corr_upper %<>% .[calibration_products, calibration_products]
```

```{r}

log_similarity_price_relative <- function(log_price_1, log_prices_2) {
  -1 * abs(log_prices_2 - log_price_1)
} 
log_similarity_price_absolute <- function(price_1, prices_2) {
  -1 * abs(prices_2 - price_1)
}
log_similarity_price <- function(price_1, prices_2, log_price_1, log_prices_2) {
  log_similarity_price_absolute(price_1, prices_2) +
  log_similarity_price_relative(log_price_1, log_prices_2)
}
```

```{r}

log_similarity_price_mat <-
sapply(calibration_products, \(product_1) {
    price_1 <- exp(log_list_prices[as.character(product_1)])
    log_price_1 <- log_list_prices[as.character(product_1)]

    prices_2 <- exp(log_list_prices[as.character(calibration_products)])
    log_prices_2 <- log_list_prices[as.character(calibration_products)]
    log_similarity_price(price_1, prices_2, log_price_1, log_prices_2)
})
log_similarity_price_mat %<>% .[calibration_products, calibration_products]
```

```{r}
log_prior_similarity_mat <-
      log( (seasonality_weekly_corr_upper/2 + .5) ) + 
      log( (seasonality_monthly_corr_upper/2 + .5) ) +
      log_similarity_price_mat
```

```{r}
#View(log_prior_similarity_mat %>% exp() %>% round(2))
```

```{r}

get_word2vec <- function(x, dim, window, iter)
{
    fname <- sprintf("models/w2v_%d_%d_%d.model", dim, window, iter)
    if (file.exists(fname)) {
      model <- word2vec::read.word2vec(file = fname)

    } else {
      set.seed(123456789)

      tic()
      model <- word2vec(x = x, type = "cbow", dim = dim, window = window, iter = iter, threads = 8L)
      word2vec::write.word2vec(model, file = fname)
      toc()
    }
    model
}

evaluate_model <- function(dim, window, iter = 10)
{
    # using: log_list_prices, transaction_baskets_df

    model <- get_word2vec(x = transaction_baskets_df$basket, dim = dim, window = window, iter = iter)
    embeddings <- as.matrix(model)

    vocabulary <- rownames(embeddings)
    selected_calibration_products <- calibration_products[calibration_products %in% vocabulary]

    word2vec_similarities <- word2vec::word2vec_similarity(
                                  embeddings[selected_calibration_products,],
                                  embeddings[selected_calibration_products,], 
                                  type = "cosine")/2 + 0.5
    log_prior_similarities <- log_prior_similarity_mat[selected_calibration_products,
                                                       selected_calibration_products]

    log_prior_similarities = as.vector(log_prior_similarities)
    log_estimated_similarities = as.vector(log(word2vec_similarities))
    
    cor(log_prior_similarities, log_estimated_similarities)
    
    plot(log_prior_similarities, log_estimated_similarities)
    
    est_res <- max_loglik_mixture_similarity(as.vector(log_prior_similarities), 
                                             as.vector(log(word2vec_similarities)))
        
    est_res$value
}
```

```{r}

evaluate_model(dim = 10, window = 10, iter = 10)

evaluate_model(dim = 50, window = 10, iter = 10)

evaluate_model(dim = 75, window = 10, iter = 10)


```

```{r}

params <- crossing(dim = c(2, 10, 20, 50, 100, 150), window = c(10, 15))
fit <- params %>% group_by(dim, window) %>% summarize( fit = evaluate_model(dim, window) )

params2 <- crossing(dim = c(200, 250, 300, 400, 500, 600), window = c(15, 20))
fit2 <- params2 %>% group_by(dim, window) %>% summarize( fit = evaluate_model(dim, window) )

params3 <- crossing(dim = c(800, 1000, 1200, 1500), window = c(15, 20, 30))
fit3 <- params3 %>% group_by(dim, window) %>% summarize( fit = evaluate_model(dim, window) )

params4 <- crossing(dim = c(1750, 2000, 2500, 3000), window = c(30, 40))
fit4 <- params4 %>% group_by(dim, window) %>% summarize( fit = evaluate_model(dim, window) )

params5 <- crossing(dim = c(5000, 7500, 10000), window = c(40, 50))
fit5 <- params5 %>% group_by(dim, window) %>% summarize( fit = evaluate_model(dim, window) )

fit %>% bind_rows(fit2) %>% bind_rows(fit3) %>% bind_rows(fit4) %>% bind_rows(fit5) %>% 
  filter(dim >= 800) %>%
  ggplot(aes(dim, fit, color = as.factor(window) )) + geom_point() + geom_line()
```

```{r}
target <- sim[[1]]$term2 == "1072523X"
log(sim[[1]]$similarity[target]) - sum(log(sim[[1]]$similarity[!target]))
# 17802.81
# 23056.73

```

```{r}

```

```{r}
sim <- predict(model, c("1123420","1123420X"), type = "nearest", top_n = n_vocabulary)

sim[[1]] %>% filter(term2 == "1123420X") %>% bind_rows( sim[[2]] %>% filter(term2 == "1123420") )
```

```{r}
sim[[1]]$similarity
```

```{r}

```
